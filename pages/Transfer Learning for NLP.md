- Transfer learning: Re-use and adapt already pre-trained supervised machine learning models on a target task
- How we can re-use and neural LMs on target tasks (e.g. text classification, machine translation, question answering, etc.)
- ((647cedd0-ee95-4f93-9f2f-1c2f0da274ca))
	- A machine learning approach where models trained on a source task (or domain) are adapted to a related target task1 (or domain)
	  一种机器学习方法，其中在源任务（或领域）上训练的模型被适应到相关的目标任务1（或领域）
- ((647cedf1-39f5-48e9-9c45-750ea1fcf1d5))
	- Domain: $\mathcal{D}=\{\mathcal{X}, P(X)\}$
	- Task: $\mathcal{T}$ where $y \in \mathcal{Y}$
	- Cond. Prob. Distrib.: $P(Y \mid X)$
	- Given a source domain $\mathcal{D}_S$ and a corresponding task $T_S$, a target domain $\mathcal{D}_T$ and task $\mathcal{T}_T$, earn a new model that computes the target conditional probability distribution $P\left(Y_T \mid X_T\right)$ in $\mathcal{D}_T$ given information from $\mathcal{D}_S$ and $\mathcal{T}_S$
- ((647ceea5-8972-4f5f-835e-93c938e98b68))
	- $\mathcal{X}_S \neq \mathcal{X}_T$
		- Different feature spaces in source and target domains, e.g. documents written in different languages (cross-lingual adaptation)
	- $P\left(X_S\right) \neq P\left(X_T\right)$
		- Different marginal probability distributions in source and target domains, e.g. restaurant reviews vs electronic product reviews (domain adaptation)
	- $\mathcal{Y}_S \neq \mathcal{Y}_T$
		- Different tasks (label sets), e.g. LM as source task and sentiment analysis as target task
	- $P\left(Y_S \mid X_S\right) \neq P\left(Y_T \mid X_T\right)$
		- Different conditional probability distributions between source and target tasks, e.g. source and target documents are unbalanced regarding to their classes
- ((647ceefa-4ee3-482b-8ed1-7d4d204d6561))
- ((647cef02-fc82-4ba2-8719-9c9df57de5ae))
- ((647cef10-bec0-4d30-b061-f1aa9e4d77d8))
- ((647cef1d-b3f4-4111-895b-9b1d1b8f9edd))
- ((647cef31-7151-4e47-bc7b-8f53744c15c1))
-