- Feedforward neural networks
- ((647a0766-f61b-4090-8682-450c120927ba))
	- Sigmoid
		- $g(z)=\sigma(z)$
	- Hyperbolic Tangent
		- $g(z)=\tanh (z)=\frac{e^{2 z}-1}{e^{2 z}+1}$
	- Rectified Linear Unit (ReLU)
		- $g(z)=\max (0, z)$
- ((647a07c4-e79f-4f67-9f6c-0a8a8f8a8fd8)) [[card]]
	- ((647a07fd-0668-4c98-ab16-d85ae74623b3))
- ((647a083e-d402-48fe-88c8-a6eb85ab9f4a)) [[card]]
	- Forward Pass
		- Compute and store all the output values of all the hidden units (for each hidden layer) and the output layer
	- Backward Pass
		- Compute the gradients for the output and hidden layers with respect to the cost function $L$ and update the weights for each layer
- ((647a08ef-a0ed-4120-9599-f9482b39b5fa))
  collapsed:: true
	- ((647a090b-f14c-4938-96eb-3cd58f9cd746))
	-
- ((647a0ab9-5d5d-46b3-ad78-05d21ad93e84)) algorithm
	- ((647a0ae1-c00e-494b-b8aa-95ce70c85849))
- ((647a0aec-6eb0-4c2e-8d2a-59344e9a4670))
	- ((647a0afc-ac36-45a8-82a4-992b48f2a9b3))
- Regularisation
	- ((647a0d36-9de9-4d75-95f8-0de88b04b18c))