file:: [com6513_1685374358009_0.pdf](../assets/com6513_1685374358009_0.pdf)
file-path:: ../assets/com6513_1685374358009_0.pdf

- [:span]
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 647e0e63-efa3-4799-8866-0b8c3e7ac618
  hl-type:: area
  hl-stamp:: 1685982818503
- Use them to tag the given word sequence by computing Ë†y
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 647e19db-b3b5-4c3a-9861-75ddac2d43f3
- Explain the equation and the approximation terms.
  ls-type:: annotation
  hl-page:: 3
  hl-color:: yellow
  id:: 647e1c7f-404c-4142-bb67-63e404b85c4f
- transition probabilities or the emission probabilities
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 647e1cac-f3cc-426b-af46-d3a52db2e5dc
- The Viterbi algorithm 
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 647f5225-b67f-4ad4-a3cb-8908346c7cce
- What are distributed word representations? How do they compare to one-hot encoding? 
  ls-type:: annotation
  hl-page:: 5
  hl-color:: yellow
  id:: 647f667a-57c8-4978-879c-7184804d5c58
- What are distributed word representations? How do they compare to one-hot encoding
  ls-type:: annotation
  hl-page:: 5
  hl-color:: yellow
  id:: 647f6681-b7a9-4393-9791-928b1e19f6fd
- Give ONE example of intrinsic word representation evaluation and ONE example of extrinsic word representation evaluation. 
  ls-type:: annotation
  hl-page:: 5
  hl-color:: yellow
  id:: 64811113-d9df-4a7b-ad9e-b384f578e798