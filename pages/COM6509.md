public:: true
alias:: Machine Learning and Adaptive Intelligence

- Cards
	- Part1
	  collapsed:: true
		- {{cards [[COM6509/Probability Theory/Cards]] }}
		  collapsed:: true
			- Summary: 2 items, 2 review counts [[2023-01-24]]
				- Remembered:   2 (100%)
				- Forgotten :   0 (0%)
			- Summary: 5 items, 5 review counts [[2023-01-23]]
				- Remembered:   3 (60%)
				- Forgotten :   2 (40%)
			- Summary: 17 items, 17 review counts [[2023-01-22]]
				- Remembered:   12 (70%)
				- Forgotten :   5 (29%)
			- Summary: 1 items, 1 review counts [[2023-01-08]]
				- Remembered:   1 (100%)
				- Forgotten :   0 (0%)
			- Summary: 7 items, 7 review counts [[2023-01-06]]
				- Remembered:   6 (85%)
				- Forgotten :   1 (14%)
	- Part2
	  collapsed:: true
		- {{cards [[COM6509/End to end/Cards]]}}
		  collapsed:: true
			- Summary: 4 items, 4 review counts [[2023-01-24]]
				- Remembered:   3 (75%)
				- Forgotten :   1 (25%)
			- Summary: 3 items, 3 review counts [[2023-01-23]]
				- Remembered:   1 (33%)
				- Forgotten :   2 (66%)
			- Summary: 9 items, 9 review counts [[2023-01-22]]
				- Remembered:   2 (22%)
				- Forgotten :   7 (77%)
	- Part3
		- {{cards [[COM6509/Decision Tree/Cards]]}}
		  collapsed:: true
			- Summary: 7 items, 7 review counts [[2023-01-24]]
				- Remembered:   1 (14%)
				- Forgotten :   6 (85%)
			- Summary: 9 items, 9 review counts [[2023-01-23]]
				- Remembered:   2 (22%)
				- Forgotten :   7 (77%)
- Resources
	- Lecture
		- ![COM4509_6509 Lecture 1.pdf](../assets/COM4509_6509_Lecture_1_1664108573059_0.pdf)
		- ![COM4509_6509 Lecture 2a.pdf](../assets/COM4509_6509_Lecture_2a_1664873971169_0.pdf)
		- ![COM4509_6509 Lecture 2b.pdf](../assets/COM4509_6509_Lecture_2b_1664873979631_0.pdf)
		- ![COM4509_6509 Lecture 3.pdf](../assets/COM4509_6509_Lecture_3_1666809397145_0.pdf)
		- ![COM4509_6509 Lecture 4.pdf](../assets/COM4509_6509_Lecture_4_1666083462950_0.pdf)
		- ![COM4509_6509 Lecture 5.pdf](../assets/COM4509_6509_Lecture_5_1667167747275_0.pdf)
		- ![Lecture 6.pdf](../assets/Lecture_6_1669310763609_0.pdf)
		- ![Lecture 7.pdf](../assets/Lecture_7_1669310826705_0.pdf)
		- ![Lecture 8.pdf](../assets/Lecture_8_1669310833445_0.pdf)
		- ![Lecture 9.pdf](../assets/Lecture_9_1671028541607_0.pdf)
		- ![Lecture 10.pdf](../assets/Lecture_10_1671028547300_0.pdf)
	- Reading List
	  collapsed:: true
		- ![Pattern Recognition and Machine Learning .pdf](../assets/Pattern_Recognition_and_Machine_Learning_1664396434429_0.pdf)
		- [[Pattern Recognition and Machine Learning]]
		- [机器学习数学基础 (itdiffer.com)](http://math.itdiffer.com/)
	- Lab
	  collapsed:: true
		- ![Exercise Sheet 1.pdf](../assets/Exercise_Sheet_1_1664396422144_0.pdf)
		  collapsed:: true
			- [[概率论]]
			  collapsed:: true
				- [[数学期望]]
				- [[标准差与方差]]
			- [[高等数学]]
				- [[多元函数积分学]]
		- ![Exercise Sheet 1 Solutions.pdf](../assets/Exercise_Sheet_1_Solutions_1664396426454_0.pdf)
	- WorkSheet
		- ![Exercise Sheet 1.pdf](../assets/Exercise_Sheet_1_1673019752248_0.pdf)
		- ![Exercise Sheet 1 Solutions.pdf](../assets/Exercise_Sheet_1_Solutions_1673019768385_0.pdf)
		- ![Exercise Sheet 2.pdf](../assets/Exercise_Sheet_2_1673281517644_0.pdf)
		- ![Exercise Sheet 2 Solutions.pdf](../assets/Exercise_Sheet_2_Solutions_1673281508436_0.pdf)
		- ![Exercise Sheet 3.pdf](../assets/Exercise_Sheet_3_1674262343001_0.pdf)
		- ![Exercise Sheet 3 Solutions.pdf](../assets/Exercise_Sheet_3_Solutions_1674262357275_0.pdf)
		- ![Exercise Sheet Lecture 4.pdf](../assets/Exercise_Sheet_Lecture_4_1666615993119_0.pdf)
		- ![Exercise Sheet 4 Solutions.pdf](../assets/Exercise_Sheet_4_Solutions_1674262348114_0.pdf)
		- ![Exercise Sheet 5.pdf](../assets/Exercise_Sheet_5_1674473528938_0.pdf)
		- ![Exercise Sheet 5 Solutions.pdf](../assets/Exercise_Sheet_5_Solutions_1674473540563_0.pdf)
		- ![Exercise Sheet 6.pdf](../assets/Exercise_Sheet_6_1674473563016_0.pdf)
		- ![Exercise Sheet 6 Solutions.pdf](../assets/Exercise_Sheet_6_Solutions_1674473553067_0.pdf)
		- ![Exercise Sheet 7.pdf](../assets/Exercise_Sheet_7_1674473576299_0.pdf)
		- ![Exercise Sheet 7 Solutions.pdf](../assets/Exercise_Sheet_7_Solutions_1674473586188_0.pdf)
		- ![Exercise Sheet 8.pdf](../assets/Exercise_Sheet_8_1674473592735_0.pdf)
		- ![Exercise Sheet 8 Solutions.pdf](../assets/Exercise_Sheet_8_Solutions_1674473599299_0.pdf)
		- ![Exercise Sheet 9.pdf](../assets/Exercise_Sheet_9_1674473606216_0.pdf)
		- ![Exercise Sheet 9 Solutions.pdf](../assets/Exercise_Sheet_9_Solutions_1674473615870_0.pdf)
		- ![Exercise Sheet 10 Solutions.pdf](../assets/Exercise_Sheet_10_Solutions_1674473622433_0.pdf)
		- ![Test.pdf](../assets/Test_1674473647143_0.pdf)
	- doc
	  collapsed:: true
		- [Pyplot tutorial — Matplotlib 3.6.0 documentation](https://matplotlib.org/stable/tutorials/introductory/pyplot.html)
- Reading
  background-color:: #793e3e
  collapsed:: true
	- pattern recognition and machine learning
		- section 1.1
- Introduction
  collapsed:: true
	- Regression And Classification
	- machine learning or statistical learning
		- statistical learning.  care more about model
	- ((6332c176-8aea-44ff-87b6-3c020fc8554d))
	  collapsed:: true
		- Training setn
		- Validation set
		- Test set
		- ((63305086-7b11-4a11-8c54-25d84c632670))
		- ((6330508f-7708-4987-9e20-d5cd50890016))
		- ((633050fc-b046-4716-942e-a36f0cf60685))
	- [[Overfitting and underfitting]]
	  collapsed:: true
		- ((6330625d-2aaa-4e3a-b486-4e51a089889b))
		- ((6330621f-efda-4189-be6d-e58e11a2d49c))
			- Need more data
		- ((63306230-b0df-4655-aa4e-1857e6ab1a85))
	- Generalisation
	  collapsed:: true
		- ((633062b4-b5d2-4add-a7f5-290e34fae4d5))
	- extrapolation
	- interpolation
	- [[Linear Regression]]
	- [[Classification Problem]] [[Logistic Regression 补充]]
	- Type of [[Machine Learning]]
		- [[Supervised learning]]
		- [[Unsupervised learning]]
		- Reinforcement learning
		- Active learning
	- ((633068c8-f4f1-4d70-a72b-7c8b0fed7e66)) (目标函数)
	- ((633068bf-7fa2-4991-9221-854434e7bddc))
		- Uncertainty quantification
		- Interpretability
		- Adversarial Examples?
	- [[概率论]]相关
		- ((63308607-3052-49f1-a98e-9b52379f1122))
			- discrete density function 离散概率分布
			- probability mass function 概率质量函数
				- 概率质量函数是对[[离散随机变量]]定义的，本身代表该值的概率； [[概率密度函数]] 函数是对连续随机变量定义的，本身不是概率，只有对连续随机变量的概率密度函数在某区间内进行积分后才是概率
		- Joint vs  conditional
			- Joint Probability 联合概率分布
			- Conditional Probability 条件概率分布
		- ((6330942b-3070-45c8-8cbf-aa1d7d0666ae)) 概率乘积法则
	- Examples: Animals in the zoo
		- ((6331fa58-1e33-47c3-b517-3cd6aa515bf7))
			- A 和 B 肯能性为二分之一.
			- B 中逃出的是老虎为 四分之一.
			- 两者相乘
	- ((6331fe10-2018-4d6a-a9fd-35ae61a8c161)) [[贝叶斯定理]]
		- P(W,J) 即W和 J 一起发生的概率
	- ((63320ced-d4ff-4bed-80da-1b3cfac041f0))
		- TODO 期望函数
		- ((6332d631-f987-4389-b571-6803e92ecfd8))
			- ((62d959ce-e1e9-4262-9d06-5c36ac765a68))
- ((63321251-cf29-4c82-8e9c-dc0cc39894eb))
  collapsed:: true
	- 假设,共200 人在岛上,如果每个人偷饼干的概率相等,则 William 偷饼干的概率为$P(X=william)=\dfrac{1}{200}$
	- $P(X)$ 为概率质量函数
	  ref:: ((63308607-3052-49f1-a98e-9b52379f1122))
		- 可参考阅读[[概率论]],第二章 随机变量及其分布,中的离散型随机变量
		- 大概意思: 是某个人偷饼干概率为二百分之一.
		- 是某两个人偷饼干的概率为二百分之二
		- 是这两百个人中的一个偷饼干的概率为 1
	- 此时再考虑一下更复杂的情况,如果是 William 偷了饼干,他偷饼干时,衣服上沾了饼干上果酱的肯能性有多大
	  ref:: ((63321704-9ebd-43f6-a04f-3fff61109aff))
	- 此时我们需要求的概率就是
		- P(沾了果酱| William 偷了饼干)
			- [[条件概率]] ((6332024e-fd96-4c97-8aa2-294094598f1b))
			- 事件 A 发生的情况下,事件 B发生的概率
	- 注意,这里和[[联合概率分布]]是不同的
		- P(沾了果酱, William 偷了饼干)
		- 这表示沾了果酱的同时偷了饼干.是下面情况中的一个
			- 偷了饼干; 沾了果酱
			- 偷了饼干; 没沾果酱
			- 没偷饼干; 沾了果酱
			- 没偷饼干; 没沾果酱
		- 而条件概率指的是,在偷了饼干的前提下
			- 沾了果酱
			- 没沾果酱
	- 此处的 ((6330942b-3070-45c8-8cbf-aa1d7d0666ae)) 指的是概率乘积法则
		- ~~可参考 [[概率乘法定理]]~~
		- 可参考 [[条件概率]],公式变形.
	- 再增加一些额外条件
	  collapsed:: true
		- 法医一般发现,小偷有百分之五十的概率会在衣服上沾果酱
		- $P(沾了果酱|William 偷了饼干)=0.5$
		- 加上我们之前就知道了的 P(W) = 1/200
		- 如何计算 P(J,W)
		- 0.5 * 1/200 = 1/400
	-
		-
-
-
- [[COM6509/Probability Theory]]
- [[COM6509/Probability Theory/Cards]]
- [[COM6509/End to end]]
- [[COM6509/End to end/Cards]]
- [[决策树]]
- [[COM6509/Decision Tree/Cards]]
- [[Linear Regression]]
- [[Gaussian Processes]]
- [[逻辑回归]]
- [[Automatic Differentiation]]
- [[Neural Networks]]
- [[Convolutional Neural Networks]]
- [[Unsupervised learning]]
- [[主成分分析]]
- [[Auto-encoders]]
- [[Clustering]]
- [[Generative Models]]
- [[Variational Auto-Encoders]]
- Advanced Concepts in ML
  collapsed:: true
	- Reproducible = Trustworthy
	- Explainability of AI
	- The energy cost of machine learning
	- Sequence modelling
	- Recurrent neural networks (RNNs)
	- Unrolling a RNN
	- Loss function accumulates through time
	- Training a RNN
	- Avoiding BPTT
- LAB
	- [[COM6509/assignment_part1]]
	- [[决策树/lab]]
	- [[COM6509/Lab6]]
- [[COM6509/PCA/Cards]]